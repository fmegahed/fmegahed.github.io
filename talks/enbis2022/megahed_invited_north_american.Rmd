---
title: "Data Preparation and Model Evaluation"
subtitle: "The Interface of Machine Learning and Statistics"
date: "28 June 2022"
output:
  xaringan::moon_reader:  
    css: 
    - default
    - css/my-theme.css
    - css/fonts.css
    lib_dir: libs
    nature:
      highlightStyle: magula
      highlightLines: true
      highlightLanguage: ["r"]
      countIncrementalSlides: false
      ratio: "16:9"
header-includes:  
  - "header.html"
author: '<br>Fadel M. Megahed, PhD <br>[`r icons::icon_style(icons::fontawesome("google"), fill = "white")` Scholar](https://scholar.google.com/citations?user=6CTlKGMAAAAJ&hl=en&oi=ao) &nbsp; |  &nbsp;
[`r icons::icon_style(icons::fontawesome("twitter"), fill = "white")` @FadelMegahed](https://twitter.com/FadelMegahed) &nbsp; | &nbsp;
[`r icons::icon_style(icons::fontawesome("github"), fill = "white")` @fmegahed](https://github.com/fmegahed) &nbsp; | &nbsp;
[`r icons::icon_style(icons::fontawesome("paper-plane", style = "solid"), fill = "white")` fmegahed@miamioh.edu](mailto:fmegahed@miamioh.edu)</br> <br>
<u><b><font color="white">Joint work with:</b></u><br>
Allison Jones-Farmer, PhD &nbsp; [`r icons::icon_style(icons::fontawesome("link", style = "solid"), fill = "white")` Miami University](https://miamioh.edu/fsb/directory/?up=/directory/farmerl2)<br/> 
Ying-Ju (Tessa) Chen, PhD &nbsp; [`r icons::icon_style(icons::fontawesome("link", style = "solid"), fill = "white")` University of Dayton](https://miamioh.edu/fsb/directory/?up=/directory/farmerl2)<br/>
Steve Rigdon, PhD &nbsp; [`r icons::icon_style(icons::fontawesome("link", style = "solid"), fill = "white")` Saint Louis University University](https://www.slu.edu/public-health-social-justice/faculty/rigdon-steven.php) <br><br><u><b><font color="white">Slides hosted at:</b></u> [`r icons::icon_style(icons::fontawesome("link", style = "solid"), fill = "white")` https://tinyurl.com/enbis22](https://tinyurl.com/enbis22) <br><br>'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = TRUE,
                      echo = FALSE,
                      warning = FALSE,
                      message = FALSE,
                      progress = FALSE, 
                      verbose = FALSE,
                      dev = 'png',
                      fig.height = 3,
                      dpi = 300,
                      fig.align = 'center')

options(htmltools.dir.version = FALSE)

miamired = '#C3142D'

if(require(pacman)==FALSE) install.packages("pacman")
if(require(devtools)==FALSE) install.packages("devtools")

if(require(countdown)==FALSE) devtools::install_github("gadenbuie/countdown")
if(require(xaringanExtra)==FALSE) devtools::install_github("gadenbuie/xaringanExtra")

if(require(icons)==FALSE) remotes::install_github("mitchelloharawild/icons")


pacman::p_load(tidyverse, magrittr, lubridate, janitor, # data analysis pkgs
               DT, # for nicely printed output
               fontawesome, RefManageR, xaringanExtra, countdown, icons,
               webshot, gifski,
               bibliometrix)
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
if(require(xaringanthemer) == FALSE) install.packages("xaringanthemer")
library(xaringanthemer)

style_mono_accent(base_color = "#84d6d3",
                  base_font_size = "20px")

xaringanExtra::use_xaringan_extra(c("tile_view", "panelset", "broadcast", "share_again", "search", "fit_screen", "clipable", "clipboard"))
```


# Statistics vs Machine Learning/ Data Science

```{r stats_vs_ml, fig.cap='A controversial definition of both statistics and machine learning', out.width='60%'}
knitr::include_graphics('imgs/stats_vs_ml.png')
```

.footnote[
<html>
<hr> 
</html>

**Source:** Bzdok, D., Altman, N., & Krzywinski, M. (2018). Statistics versus machine learning. Nature Methods, 15(4), 233-234 [[Paper Link](https://www.nature.com/articles/nmeth.4642.pdf)].

]

---
class: inverse, center, middle


# The "Science of Data Science [ML]": A Statistical Lense

.footnote[
.left[
<html>
<hr>
<html>

**.white[Source:]** A significant portion of the content in this section is motivated and/or based on the insights shared in  Donoho, D. (2017). 50 years of data science. Journal of Computational and Graphical Statistics, 26(4), 745-766. [Paper Link](https://www.tandfonline.com/doi/full/10.1080/10618600.2017.1384734)]
]


---

# Overarching Goal for Today's Talk

.content-box-red[
.bold[.black[How can applied statisticians inform the practice of machine learning and data science?]]
]

### Some Guiding Questions

1. We cannot be the first to suggest this. So generally speaking, **what have the giants of our field have done/suggested?**   

2. **Where should we start?** It is unreasonable to start by examining the state-of-the-art large language models (LLM) used in many of the sub fields of natural language processing.  
  + The *InstructGPT* model has 175,000,000,000 (175 billion) parameters; and   
  + The *PaLM* model has 540,000,000,000 (540 billion) parameters.

.footnote[
<html>
<hr>
</html>

**Source:** The information pertaining to those LLMs is based on Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., & Iwasawa, Y. (2022). Large Language Models are Zero-Shot Reasoners. [arXiv preprint arXiv:2205.11916v2](https://arxiv.org/abs/2205.11916) (published on 9 June 2022).
]


---

# The Science of Data ~~Analysis~~ Science (1962)

.font90[
> _For a long time I have thought I was a **statistician**, interested in inferences from the particular to the general. ... All in all I have come to feel that my central interest is in **data analysis**, which I take to include, among other things: <u>procedures for analyzing data</u>, <u>techniques for interpreting the results of such procedures</u>, <u>ways of planning the gathering of data to make its analysis easier, more precise or more accurate</u>, and <u>all the machinery and results of (mathematical) statistics which apply to analyzing data</u> ..._ 

> _**Data analysis and the parts of statistics** which adhere to it, must then take on the **characteristics of a science** ..._  

> _... **data analysis is a very difficult field. It must adapt itself to what people can and need to do with data.** ... It is too much to ask for close and effective guidance for data analysis from any highly formalized structure, either now or in the near future ..._

> _Data analysis can gain much from formal statistics, but only if the **connection is kept adequately loose**._
]

.footnote[
<html>
<hr>
</html>

**Source:** The above four quotes are from Tukey, J. W. (1962). The future of data analysis. The Annals of Mathematical Statistics, 33(1), 1-67. [Paper Link](https://www.jstor.org/stable/2237638) 
]


---

# Greater or Lesser Statistics, A Choice for Future Research (1993)

> The **statistics profession** faces a choice in its future research between continuing concentration on traditional topics—based largely on data analysis supported by mathematical statistics—and a broader viewpoint—based on an **inclusive concept of learning from data**. The **latter course presents severe challenges as well as exciting opportunities**. The former risks seeing statistics become increasingly marginal … -- John Chambers, co-developer of S Language

.footnote[
<html>
<hr>
</html>

**Source:** Chambers, J. M. (1993). Greater or lesser statistics: a choice for future research. Statistics and Computing, 3(4), 182-184. [Paper Link](https://link.springer.com/article/10.1007/BF00141776) 
]


---
class: inverse, center, middle

# An Area where Statistics Can Influence Machine Learning Research


---

# Interpretable and Explainable Models

.pull-left[
.center[
![Book Cover image for Weapons of Math Destruction by Cathy O'Neil](https://images-na.ssl-images-amazon.com/images/I/51eUw-v0X+L._SX329_BO1,204,203,200_.jpg)
]
]

.pull-right[
.center[
![Book Cover Image of Algorithms of Opression by Safuya Umoja Noble](https://images-na.ssl-images-amazon.com/images/I/51obBtKNC5L._SX331_BO1,204,203,200_.jpg)
]
]


---

# Taxonomy of Research in this Space

<html>
<center>
<img src="https://ars.els-cdn.com/content/image/1-s2.0-S1566253519308103-gr11_lrg.jpg" width="74%" height="74%" alt="Two alternate taxonomies for categorizing the relevant literature in explainable AI "/>
</center>
</html>
.center[Two alternate taxonomies for categorizing the relevant literature in explainable AI]

.footnote[
<html>
<hr>
</html>

**Source:** Arrieta, A. B., Díaz-Rodríguez, N., Del Ser, J., Bennetot, A., Tabik, S., Barbado, A., ... & Herrera, F. (2020). Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI. Information Fusion, 58, 82-115. [Paper Link](https://www.sciencedirect.com/science/article/pii/S1566253519308103)
]

---

# Explainable Techniques in Action: LIME

<html>
<center>
<img src="https://ars.els-cdn.com/content/image/1-s2.0-S1566253519308103-gr9_lrg.jpg" alt="Examples of explanation when using LIME on images"/>
</center>
</html>
.center[Examples of explanation when using LIME on images]


.footnote[
<html>
<hr>
</html>

**Source:** Ribeiro, M. T., Singh, S., & Guestrin, C. (2016, August). " Why should i trust you?" Explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining (pp. 1135-1144). [Arxiv Paper Link](https://arxiv.org/abs/1602.04938)
]


---
class: inverse, center, middle

# Our Work in the Interface between Statistics and ML

## Insights from Experimental Design


---

# Target Audience: Citizen Data Scientists


<html>
<center>
<img src="https://ars.els-cdn.com/content/image/1-s2.0-S1566253519308103-gr2_lrg.jpg" width="91%" height="91%" alt="Diagram showing the different purposes of explainability in ML models sought by different audience profiles. Two goals occur to prevail across them: need for model understanding, and regulatory compliance."/>
</center>
</html>
.center[Diagram showing the different purposes of explainability in ML models sought by different audience profiles.]

.footnote[
<html>
<hr>
</html>

**Source:** The term 'citizen data scientists' was coined by Gartner to capture "a person who creates or generates models that leverage predictive or prescriptive analytics, but whose primary job function is outside of the field of statistics and analytics." [Article Link](https://www.gartner.com/smarterwithgartner/how-to-use-citizen-data-scientists-to-maximize-your-da-strategy).

**Image Source:** Arrieta, A. B., Díaz-Rodríguez, N., Del Ser, J., Bennetot, A., Tabik, S., Barbado, A., ... & Herrera, F. (2020). Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI. Information fusion, 58, 82-115. [Paper Link](https://www.sciencedirect.com/science/article/pii/S1566253519308103)
]


---

# Frameworks Used in ML Projects

.center[
[![CRISP-DM is the Most Popular Data Mining Framework](https://www.datascience-pm.com/wp-content/uploads/2020/10/process-google-search-volume-2019-2020.png)](https://www.datascience-pm.com/crisp-dm-still-most-popular/)
]

.footnote[
<html>
<hr>
</html>


**Image Source:** Saltz, J. (2022). CRISP-DM is Still the Most Popular Framework for Executing Data Science Projects. Data Science Process Alliance Blog. ([Webpage Link](https://www.datascience-pm.com/crisp-dm-still-most-popular/), last updated on May 2, 2022)
]

---

# The CRISP-DM Framework

```{r crisp_dm, out.width='45%', fig.alt='The CRISP DM Framework'}
knitr::include_graphics("https://upload.wikimedia.org/wikipedia/commons/b/b9/CRISP-DM_Process_Diagram.png")
```


.footnote[
<html>
<hr>
</html>


**Image Source:** From the Wikipedia article titled "Cross-industry standard process for data mining" [Link](https://en.wikipedia.org/wiki/Cross-industry_standard_process_for_data_mining)
]

---

# Issues with Frameworks Such as CRISP-DM

.font90[
```{python setup_fn, echo = T, eval = F}
exp = setup(df, target = 'died', train_size = 0.8,
            ordinal_features = {'zipinc_qrtl' : ['FirstQ', 'SecondQ', 'ThirdQ', 'FourthQ']},
            ignore_features = ['id'], 
            # decisions made when analyzing real and complex data
            preprocess = True, #<<
            # handling multicollinearity
            remove_multicollinearity= True, #<<
            # feature selection and approach to feature selection
            feature_selection = True, feature_selection_method = 'classic', #<<
            # which normalization method to be applied on numeric variables
            normalize = True, normalize_method = 'minmax', #<<
            # how to handle missing and unknown data
            imputation_type = 'iterative', #<<
            numeric_imputation = 'mean', categorical_imputation = 'constant', #<<
            handle_unknown_categorical = True, #<<
            # how to handle imbalanced data for classification purposes
            fix_imbalance = True, #<<
            fix_imbalance_method = up_sample, #<<
            # type of cross validation strategy to be used
            fold_strategy = 'stratifiedkfold', #<<
            fold = 10, n_jobs = -1,
            session_id=2022, experiment_name='tavr_up', log_experiment=True)
```
]




---

# Practical Gaps

.content-box-red[
Frameworks, such as CRISP-DM, highlight the **iterative nature** of **KDDM projects** in terms of the need to iterate through steps in the model-fitting process. However, they do **not** explain **how** to iterate or **when** the user should stop iterating.  

.bold[.black[Most practical implementations resort to trial-and-error experimentation at each decision point in the modeling process.]]  
  + Focus is on .bold[.black[main effects of changing one aspect of the model fitting process]].  
  + This is like experimentation by changing .bold[.black[one factor at a time (OFAT)]] and translates to researchers and/or practitioners making decisions about the model they are fitting based on preliminary analyses that involve a limited number of experimental trials.  
  + Results obtained from a .bold[.black[sequence of OFAT decisions used throughout the KDDM process may be a substandard model]].
]


---

# Bibliometric-Driven Taxonomy of DoE in KDDM


```{r doe_lit_kddm, fig.alt='The relevant literature on the use of experimental design for knowledge discovery and data mining (KDDM), showing two streams: (a) feature selection, and (b) model tuning', out.width='70%'}
knitr::include_graphics("imgs/histplot.png")
```

.footnote[
<html>
<hr>
</html>

**Image Source:** A review of the literature using experimental design for knowledge discovery and data mining, which we showed in Ahady Dolatsara, H., Chen, Y. J., Leonard, R. D., .bold[Megahed, F. M.], & Jones-Farmer, L. A. (2021). Explaining Predictive Model Performance: An Experimental Study of Data Preparation and Model Choice. Big Data. [Paper Link](https://www.researchgate.net/publication/355112734_Explaining_Predictive_Model_Performance_An_Experimental_Study_of_Data_Preparation_and_Model_Choice)
]

---

# Our Framework for How DoE can Inform KDDM



.center[
<img src="imgs/big_data_paper_framework.png" width="80%" alt="An overview of how experimental design can be used to inform the decisions made within the KDDM process">
]

.footnote[
<html>
<hr>
</html>

**Source:** Ahady Dolatsara, H., Chen, Y. J., Leonard, R. D., .bold[Megahed, F. M.], & Jones-Farmer, L. A. (2021). Explaining Predictive Model Performance: An Experimental Study of Data Preparation and Model Choice. Big Data. [Paper Link](https://www.researchgate.net/publication/355112734_Explaining_Predictive_Model_Performance_An_Experimental_Study_of_Data_Preparation_and_Model_Choice)
]


---

# Experiment Using a Heart Transplant Dataset

### United Network for Organ Sharing (UNOS)

- The [United Network for Organ Sharing (UNOS)](https://unos.org/) is a nonprofit association that manages the U.S. organ transplantation system and database.  

- Our UNOS dataset contained 129 predictors (43 numeric and 86 categorical) and 45,005 observations.    
   + The imbalance ratio in the response variable is ~ 6.29 (where 1-year graft survival = 38,829 & failure = 6,176 cases)  

.footnote[
<html>
<hr>
</html>

**Source:** Ahady Dolatsara, H., Chen, Y. J., Leonard, R. D., .bold[Megahed, F. M.], & Jones-Farmer, L. A. (2021). Explaining Predictive Model Performance: An Experimental Study of Data Preparation and Model Choice. Big Data. [Paper Link](https://www.researchgate.net/publication/355112734_Explaining_Predictive_Model_Performance_An_Experimental_Study_of_Data_Preparation_and_Model_Choice)
]

---

# Experiment Using a Heart Transplant Dataset

### Experimental Factors

  1. **Categorical imputation (4 levels):** (a) no imputation (drop), (b) mode, (c) missing (i.e., `NA`), and (d) unknown.  
  2. **Numerical Imputation (2 levels):** (a) no imputation (drop), and (b) median.   
  3. **Encoding (2 levels):** (a) label, and (b) one-hot.   
  4. **Subsampling (5 levels):** (a) none, (b) down sampling, (c) up sampling, (d) SMOTE, and (e) ROSE.   
  5. **Feature Selection (3 levels):** (a) fast feature selection, (b) LASSO, and (c) random forest.  
  6. **Algorithm: (9 levels)** (a) ANN, (b) DT, (c) ElasticNet, (d) Kernel Partial Least Square Regression, (d) LDA, (e) LR, (f) NB, (g) RF, and (h) XGB


.footnote[
<html>
<hr>
</html>

**Source:** Ahady Dolatsara, H., Chen, Y. J., Leonard, R. D., .bold[Megahed, F. M.], & Jones-Farmer, L. A. (2021). Explaining Predictive Model Performance: An Experimental Study of Data Preparation and Model Choice. Big Data. [Paper Link](https://www.researchgate.net/publication/355112734_Explaining_Predictive_Model_Performance_An_Experimental_Study_of_Data_Preparation_and_Model_Choice)
]


---

# Experiment Using a Heart Transplant Dataset

### Total Number of Experimental Runs

$4 \times 2 \times 2 \times 5 \times 3 \times 9 = 2160 \times 5$ (holdout samples) $= 10,800$

### Experimental Setup

The 10,800 ML models were fitted to the UNOS data set using an Intel Xeon processor-based
supercomputer containing 23,392 CPU cores, with a typical 28 cores/node setup and memory per node of 128 GB.

.footnote[
<html>
<hr>
</html>

**Source:** Ahady Dolatsara, H., Chen, Y. J., Leonard, R. D., .bold[Megahed, F. M.], & Jones-Farmer, L. A. (2021). Explaining Predictive Model Performance: An Experimental Study of Data Preparation and Model Choice. Big Data. [Paper Link](https://www.researchgate.net/publication/355112734_Explaining_Predictive_Model_Performance_An_Experimental_Study_of_Data_Preparation_and_Model_Choice)
]


---

# Analyzing AUC w/ Hierarchical Regression

.content-box-red[
To best reflect the sequential nature in which an analyst fits a predictive model,
.bold[.black[the factors will be entered into the study in four steps]] so that the additional variability accounted for by the factors entered can be evaluated.] 

- **Analysis 1:** *categorical imputation*, *numerical imputation*, *categorical encoding*, and the two-factor (pairwise) interactions among these three factors;  

- **Analysis 2:** *subsampling* method and the two factor interactions among subsampling method
and factors in Analysis 1;  

- **Analysis 3:** *feature selection* approach, *algorithm*, and the two-factor interactions among these two factors and the factors in Analyses 1 and 2;

- **Analysis 4:** *reduced model* — the full model from Analysis 3 will be reduced using the practical significance of the effects (<html> &eta;<sup>2</sup> </html>).


---

# Experimental Results

.panelset.sideways[

.panel[.panel-name[**Summary of the Four Analysis**]

.font75[
<html>
<table text-align='right'><thead><tr><td><b>Analysis</b></td><td><b>R<sup>2</sup></b></td><td><b>&Delta; R<sup>2</sup></b></td><td><b>&Delta; F</b></td><td><b>df<sub>1</sub></b></td><td><b>df<sub>2</sub></b></td><td><b>Sig &Delta; F</b></td></tr></thead><tbody><tr><td>1</td><td>0.010</td></tr><tr><td>2</td><td>0.254</td><td>0.244</td><td>146.25</td><td>24</td><td>10770</td><td>0.000</td></tr><tr><td>3</td><td>0.894</td><td>0.640</td><td>554.32</td><td>116</td><td>10746</td><td>0.000</td></tr><tr><td>4</td><td>0.890</td><td>-0.004</td><td>5.33</td><td>79</td><td>10703</td><td>0.000</td></tr></tbody></table>
</html>
]

]

.panel[.panel-name[**Analysis 4: ANOVA Table**]

.font75[
<html>
<table text-align='right'><thead><tr><td><b>Analysis 4</b></td><td><b>Type II Sum of Squares</b></td><td><b>df</b></td><td><b>F value</b></td><td><b>Pr(&gt;F)</b></td></tr></thead><tbody><tr><td>numerical imputation</td><td>0.065</td><td>1</td><td>158.661</td><td>0.000</td></tr><tr><td>categorical imputation</td><td>0.172</td><td>3</td><td>140.381</td><td>0.000</td></tr><tr><td>subsampling</td><td>9.667</td><td>4</td><td>5927.912</td><td>0.000</td></tr><tr><td>feature selection</td><td>0.713</td><td>2</td><td>874.381</td><td>0.000</td></tr><tr><td>algorithm</td><td>5.658</td><td>8</td><td>1734.822</td><td>0.000</td></tr><tr><td>numerical imputation &times; categorical imputation</td><td>0.152</td><td>3</td><td>124.332</td><td>0.000</td></tr><tr><td>numerical imputation &times; feature selection</td><td>0.097</td><td>2</td><td>118.763</td><td>0.000</td></tr><tr><td>subsampling &times; feature selection</td><td>0.103</td><td>8</td><td>31.493</td><td>0.000</td></tr><tr><td>subsampling &times; algorithm</td><td>17.736</td><td>32</td><td>1359.500</td><td>0.000</td></tr><tr><td>feature selection &times; algorithm</td><td>1.031</td><td>16</td><td>158.080</td><td>0.000</td></tr><tr><td>residuals</td><td>4.363</td><td>10703</td><td></td><td></td></tr></tbody></table>
</html>
]
]

.panel[.panel-name[**Analysis 4: Pairwise Interactions**]

```{r interactions, include=FALSE}
int_figs = list.files(path = "imgs/", pattern = 'interaction', full.names = T)

gifski(int_figs, gif_file = "imgs/interactions.gif", 
       width = 9600, height = 7200, delay = 5)
```

```{r interactions_gif, out.width='75%', fig.alt='An animated gif depicting the significant pairwise interactions'}
knitr::include_graphics("imgs/interactions.gif")
```

]

]


.footnote[
<html>
<hr>
</html>

**Source:** Ahady Dolatsara, H., Chen, Y. J., Leonard, R. D., .bold[Megahed, F. M.], & Jones-Farmer, L. A. (2021). Explaining Predictive Model Performance: An Experimental Study of Data Preparation and Model Choice. Big Data. [Paper Link](https://www.researchgate.net/publication/355112734_Explaining_Predictive_Model_Performance_An_Experimental_Study_of_Data_Preparation_and_Model_Choice)
]


---

# Key Takeaways


.content-box-red[

- .bold[.black[Experimental design can inform the selection of an appropriate design strategy based on the available computer resources.]]

- .bold[.black[The use of ANOVA/regression can explain how the predictive performance varies with the decisions made during the KDDM process.]]

- .bold[.black[The approach can be scaled up/down.]]   
   + .bold[.black[In our followup study, using 58 different datasets from the [KEEL repository](https://sci2s.ugr.es/keel/imbalanced.php?order=ins#subA), we examined the impact of class imbalance on the performance of four subsampling strategies and two algorithms (see [Code](https://ying-ju.github.io/subsampling.github.io/#45_Hierarchical_Regression) and [Paper Link](https://doi.org/10.1038/s41592-021-01302-4) for more details). ]]
]


---

class: inverse, center, middle

# Our Work in the Interface between Statistics and ML

## Tuning Survival/Death Probabilities for Multi-Period Predictions

.footnote[
<html>
<hr>
<html>

.white[.bold[Source:]] Dolatsara, H. A., Chen, Y. J., Evans, C., Gupta, A., & Megahed, F. M. (2020). A two-stage machine learning framework to predict heart transplantation survival probabilities over time with a monotonic probability constraint. Decision Support Systems, 137, 113363. ([Paper Link](https://www.researchgate.net/publication/343338979_A_two-stage_machine_learning_framework_to_predict_heart_transplantation_survival_probabilities_over_time_with_a_monotonic_probability_constraint))
]

---

# Research Gaps

.pull-left[
- Develop **independent ML models** for each time-period  (e.g., see [Yoon 2018](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0194985) )
  
- Utilize a **sequential prediction** approach where the
“survival” probability from time periods $1, \dots, t$ are inputs to predict the survival at time $t+1$  (e.g., see [Ohno-Machdo  1997](https://www.sciencedirect.com/science/article/pii/S0010482597000085))
  
- Predict the outcome probability for one time-period and use the
**population’s survival outcomes to calibrate** other periods’ probabilities (e.g., see [Medved 2018](https://www.nature.com/articles/s41598-018-21417-7))
]

.pull-right[

.center[**What we really want**]

```{r isotonic_gif, out.width='100%', fig.alt='Proposed use of isotonic regression to tune survival probabilities'}
knitr::include_graphics("imgs/isotonic.gif")
```

]


---

# Our Two-Stage Approach

```{r isotonic_framework, out.width='80%', fig.alt='Adopting the proposed two-stage framework to obtain monotonically decreasing heart transplantation survival probabilities over time.'}
knitr::include_graphics("https://ars.els-cdn.com/content/image/1-s2.0-S0167923620301184-gr3_lrg.jpg")
```


---

# Our Results 

.panelset[

.panel[.panel-name[**Sample Patient Predictions**]

```{r sample_patients, out.width='35%', fig.alt='Plots of the forecast probabilities for four sample patients at years 1 − 10 post transplant. The light and dark blue lines show the probabilities before and after the application of isotonic regression, respectively. Note when the dark blue line is not shown, this equates to a perfect overlap with the light blue line.'}
knitr::include_graphics("https://ars.els-cdn.com/content/image/1-s2.0-S0167923620301184-gr6_lrg.jpg")
```

]

.panel[.panel-name[**Unexpected Improvements in Predictive Metrics**]

.center[**Differences (after isotonic regression – before isotonic regression) in the holdout performance**]

.font75[
<html>
<table>
<thead>
  <tr>
    <th></th>
    <th><span style="font-weight:700">Month 1</span></th>
    <th><span style="font-weight:700">Year 1</span></th>
    <th><span style="font-weight:700">Year 2</span></th>
    <th><span style="font-weight:700">Year 3</span></th>
    <th><span style="font-weight:700">Year 4</span></th>
    <th><span style="font-weight:700">Year 5</span></th>
    <th><span style="font-weight:700">Year 6</span></th>
    <th><span style="font-weight:700">Year 7</span></th>
    <th><span style="font-weight:700">Year 8</span></th>
    <th><span style="font-weight:700">Year 9</span></th>
    <th><span style="font-weight:700">Year 10</span></th>
  </tr>
</thead>
<tbody>
  <tr>
    <td><span style="font-weight:bolder">&Delta; AUC</span></td>
    <td><span style="font-weight:bolder">0.008</span></td>
    <td><span style="font-weight:bolder">0.017</span></td>
    <td><span style="font-weight:bolder">0.029</span></td>
    <td><span style="font-weight:bolder">0.021</span></td>
    <td><span style="font-weight:bolder">0.011</span></td>
    <td><span style="font-weight:bolder">0.007</span></td>
    <td><span style="font-weight:bolder">0.001</span></td>
    <td><span style="font-weight:bolder">0.001</span></td>
    <td><span style="font-weight:bolder">0.000</span></td>
    <td><span style="font-weight:bolder">0.002</span></td>
    <td><span style="font-weight:bolder">0.001</span></td>
  </tr>
  <tr>
    <td><span style="font-weight:bolder">&Delta; Accuracy</span></td>
    <td><span style="font-weight:bolder">0.125</span></td>
    <td><span style="font-weight:bolder">0.083</span></td>
    <td><span style="font-weight:bolder">0.061</span></td>
    <td><span style="font-weight:bolder">0.042</span></td>
    <td><span style="font-weight:bolder">0.017</span></td>
    <td><span style="font-weight:bolder">0.007</span></td>
    <td>−0.005</td>
    <td>−0.008</td>
    <td>−0.006</td>
    <td><span style="font-weight:bolder">0.001</span></td>
    <td><span style="font-weight:bolder">0.008</span></td>
  </tr>
  <tr>
    <td><span style="font-weight:bolder">&Delta; Sensitivity</span></td>
    <td><span style="font-weight:bolder">0.150</span></td>
    <td><span style="font-weight:bolder">0.136</span></td>
    <td><span style="font-weight:bolder">0.110</span></td>
    <td><span style="font-weight:bolder">0.083</span></td>
    <td><span style="font-weight:bolder">0.032</span></td>
    <td><span style="font-weight:bolder">0.007</span></td>
    <td>−0.037</td>
    <td>−0.061</td>
    <td>−0.102</td>
    <td>−0.130</td>
    <td>−0.161</td>
  </tr>
  <tr>
    <td><span style="font-weight:bolder">&Delta; Specificity</span></td>
    <td>−0.114</td>
    <td>−0.105</td>
    <td>−0.064</td>
    <td>−0.047</td>
    <td>−0.009</td>
    <td><span style="font-weight:bolder">0.008</span></td>
    <td><span style="font-weight:bolder">0.034</span></td>
    <td><span style="font-weight:bolder">0.050</span></td>
    <td><span style="font-weight:bolder">0.087</span></td>
    <td><span style="font-weight:bolder">0.112</span></td>
    <td><span style="font-weight:bolder">0.134</span></td>
  </tr>
  <tr>
    <td><span style="font-weight:bolder">&Delta; G-Mean</span></td>
    <td><span style="font-weight:bolder">0.009</span></td>
    <td><span style="font-weight:bolder">0.010</span></td>
    <td><span style="font-weight:bolder">0.019</span></td>
    <td><span style="font-weight:bolder">0.016</span></td>
    <td><span style="font-weight:bolder">0.010</span></td>
    <td><span style="font-weight:bolder">0.007</span></td>
    <td><span style="font-weight:bolder">0.000</span></td>
    <td>−0.003</td>
    <td>−0.003</td>
    <td>−0.001</td>
    <td>−0.005</td>
  </tr>
</tbody>
</table>
</html>
]
]
]

.footnote[
<html>
<hr>
</html>

**Source:** Dolatsara, H. A., Chen, Y. J., Evans, C., Gupta, A., & Megahed, F. M. (2020). A two-stage machine learning framework to predict heart transplantation survival probabilities over time with a monotonic probability constraint. Decision Support Systems, 137, 113363. ([Paper Link](https://www.researchgate.net/publication/343338979_A_two-stage_machine_learning_framework_to_predict_heart_transplantation_survival_probabilities_over_time_with_a_monotonic_probability_constraint))
]


---

class: inverse, center, middle

# Our Work in the Interface between Statistics and ML

## The Variability in Commonly Used Classification Metrics with Class Imbalance

.footnote[
<html>
<hr>
<html>

.white[.bold[Source:]] Work in Progress (see [Code](https://fmegahed.github.io/research/classification/metrics_variability.html) and [App](http://rstudio.fsb.miamioh.edu:3838/megahefm/metric_interpretation/) for more details)
]

---

# Research Question: Baseline sensitivity?

```{r covid_deaths, fig.alt='Four clusters of 3,108 U.S. counties according to time-series profile of COVID-19 deaths', out.width='50%'}
knitr::include_graphics('https://raw.githubusercontent.com/fmegahed/covid19-deaths/master/Figures/clusterMap.png')
```

.footnote[
<html>
<hr>
</html>

**Notes:** Counties in each cluster are: C1 (n = 1261) C2 (n = 226) C3 (n = 827) C4 (n = 794).  

**Source:** Megahed, F. M., Jones-Farmer, L. A., Ma, Y., & Rigdon, S. (2022). A Two-Stage Time Series Clustering Framework for Explaining the Varying Patterns of COVID-19 Deaths across the US. JMIR Public Health and Surveillance. ([Paper Link](https://preprints.jmir.org/preprint/32164/accepted) and [Code](https://fmegahed.github.io/covid_deaths.html))
]


---

# Our Simplified Simulation Approach


.font60[
```{r sim_fun, eval=FALSE, echo=TRUE}
sim_function = function(data = NULL, base_class_name = 'class_'){
  
  # extracting the relevant features from the data 
  number_classes = data$num_classes
  number_observations = data$num_observations
  first_class_percentage = data$first_class_perc
  prediction_approach = data$pred_approach

  # generating the reference data
  ref = sample(x = c(paste0(base_class_name, 1:number_classes)),
               size = number_observations,
               replace = T,
               prob = c(first_class_percentage, #<<
                        rep( (1-first_class_percentage)/(number_classes - 1),#<<
                             (number_classes -1 ) ) ) ) %>% #<<
    factor(levels = paste0(base_class_name, 1:number_classes) )
  
  # generating the predictions
  if(prediction_approach == 'proportional'){
    predictions = sample(
      x = c(paste0(base_class_name, 1:number_classes)),
      size = number_observations,
      replace = T,
      prob = c(first_class_percentage, #<<
               rep( (1-first_class_percentage)/(number_classes - 1), #<<
                    (number_classes -1 ) ) ) ) %>% #<<
      factor(levels = paste0(base_class_name, 1:number_classes) )
  } else{
    predictions = sample(
      x = c(paste0(base_class_name, 1:number_classes)),
      size = number_observations,
      replace = T,
      prob = rep(1/number_classes, number_classes) #<<
    ) %>% factor(levels = paste0(base_class_name, 1:number_classes) )
  }
  
  
  # computing the classification performance metrics of interest
  acc_metrics = tibble(
    accuracy = yardstick::accuracy_vec(truth = ref, estimate = predictions),
    sensitivity = yardstick::sens_vec(truth = ref, estimate = predictions, 
                                      event_level = 'first'),
    specificity = yardstick::spec_vec(truth = ref, estimate = predictions, 
                                      event_level = 'first'),
    f_measure = yardstick::f_meas_vec(truth = ref, estimate = predictions, 
                                      event_level = 'first'),
    g_mean = g_mean(x = sensitivity, y = specificity)
  )
  
  return(acc_metrics)
}
```
]


---

# Sample Results

```{r metrics, out.width='55%'}
knitr::include_graphics('imgs/sens_plot.png')
```

---
class: inverse, center, middle

# Concluding Remarks

---

# Open Questions

1. How should researchers and practitioners balance predictive accuracy with interpretation? After all, the "best" models may not always have the highest predictive accuracy.  

2. What does explainable predictive modeling mean in the context of "online learning" ML models? Should this be an online or a batch process?  

3. What should be the standard for novel statistical theories and contributions to ensure that their impact is transdiscplinary? 

--

> Aspects of scientific method are discussed: In particular, its representation  as a motivated iteration in which, in succession, practice confronts theory, and theory, practice. Rapid progress requires sufficient flexibility to profit from such confrontations, and the ability to devise parsimonious but effective models, to worry selectively about model inadequacies and to employ mathematics skillfully but appropriately. . -- George Box, 1976

.footnote[
<html>
<hr>
</html>

**Source:** Box, G. E. (1976). Science and statistics. Journal of the American Statistical Association, 71(356), 791-799. [Article Link](https://www.tandfonline.com/doi/abs/10.1080/01621459.1976.10480949)
]

---

# A Plug for the JQT Case Study Section

```{r jqt_case_studies, fig.alt='Instructions for the JQT Case Study Section', out.width='80%'}
knitr::include_graphics('imgs/jqt_instructions.PNG')

```

---
class: center, middle, inverse, title-slide

.title[
# Data Preparation and Model Evaluation
]
.subtitle[
## The Interface of Machine Learning and Statistics
]
.author[
### <br>Fadel M. Megahed, PhD <br><a href="https://scholar.google.com/citations?user=6CTlKGMAAAAJ&amp;hl=en&amp;oi=ao"><svg viewBox="0 0 488 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:white;" xmlns="http://www.w3.org/2000/svg"> <path d="M488 261.8C488 403.3 391.1 504 248 504 110.8 504 0 393.2 0 256S110.8 8 248 8c66.8 0 123 24.5 166.3 64.9l-67.5 64.9C258.5 52.6 94.3 116.6 94.3 256c0 86.5 69.1 156.6 153.7 156.6 98.2 0 135-70.4 140.8-106.9H248v-85.3h236.1c2.3 12.7 3.9 24.9 3.9 41.4z"></path></svg> Scholar</a>   |   <a href="https://twitter.com/FadelMegahed"><svg viewBox="0 0 512 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:white;" xmlns="http://www.w3.org/2000/svg"> <path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg> <span class="citation">@FadelMegahed</span></a>   |   <a href="https://github.com/fmegahed"><svg viewBox="0 0 496 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:white;" xmlns="http://www.w3.org/2000/svg"> <path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg> <span class="citation">@fmegahed</span></a>   |   <a href="mailto:fmegahed@miamioh.edu"><svg viewBox="0 0 512 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:white;" xmlns="http://www.w3.org/2000/svg"> <path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"></path></svg> fmegahed@miamioh.edu</a></br> <br> <u><b><font color="white">Joint work with:</b></u><br> Allison Jones-Farmer, PhD   <a href="https://miamioh.edu/fsb/directory/?up=/directory/farmerl2"><svg viewBox="0 0 512 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:white;" xmlns="http://www.w3.org/2000/svg"> <path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg> Miami University</a><br/> Ying-Ju (Tessa) Chen, PhD   <a href="https://miamioh.edu/fsb/directory/?up=/directory/farmerl2"><svg viewBox="0 0 512 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:white;" xmlns="http://www.w3.org/2000/svg"> <path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg> University of Dayton</a><br/> Steve Rigdon, PhD   <a href="https://www.slu.edu/public-health-social-justice/faculty/rigdon-steven.php"><svg viewBox="0 0 512 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:white;" xmlns="http://www.w3.org/2000/svg"> <path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg> Saint Louis University University</a> <br><br><u><b><font color="white">Slides hosted at:</b></u> <a href="https://tinyurl.com/enbis22"><svg viewBox="0 0 512 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:white;" xmlns="http://www.w3.org/2000/svg"> <path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg> https://tinyurl.com/enbis22</a> <br><br>
]
.date[
### 28 June 2022
]
