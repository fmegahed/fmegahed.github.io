<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>How generative AI models such as ChatGPT can be (mis)used in SPC practice, education, and research?</title>
    <meta charset="utf-8" />
    <meta name="author" content="Fadel M. Megahed, PhD    Scholar   |     @FadelMegahed   |     @fmegahed   |     fmegahed@miamioh.edu   Joint work with:  Ying-Ju (Tessa) Chen, PhD     University of Dayton  Joshua A. Ferris, PhD     Miami University  Sven Knoth, PhD     Helmut-Schmidt-Universität  Allison Jones-Farmer, PhD     Miami University  " />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/xaringanExtra-extra-styles/xaringanExtra-extra-styles.css" rel="stylesheet" />
    <link href="libs/tile-view/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view/tile-view.js"></script>
    <link href="libs/animate.css/animate.xaringan.css" rel="stylesheet" />
    <link href="libs/tachyons/tachyons.min.css" rel="stylesheet" />
    <script src="libs/xaringanExtra_fit-screen/fit-screen.js"></script>
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
    <script type="application/json" id="xaringanExtra-editable-docid">{"id":"xfd82219c60742fab84413dd31c089f6","expires":14}</script>
    <script src="libs/himalaya/himalaya.js"></script>
    <script src="libs/js-cookie/js.cookie.js"></script>
    <link href="libs/editable/editable.css" rel="stylesheet" />
    <script src="libs/editable/editable.js"></script>
    <script src="libs/clipboard/clipboard.min.js"></script>
    <link href="libs/xaringanExtra-clipboard/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-clipboard/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"Copy Code","success":"Copied!","error":"Press Ctrl+C to Copy"})</script>
    <link href="libs/shareon/shareon.min.css" rel="stylesheet" />
    <script src="libs/shareon/shareon.min.js"></script>
    <link href="libs/xaringanExtra-shareagain/shareagain.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-shareagain/shareagain.js"></script>
    <script src="libs/mark.js/mark.min.js"></script>
    <link href="libs/xaringanExtra-search/search.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-search/search.js"></script>
    <script>window.addEventListener('load', function() { window.xeSearch = new RemarkSearch({"position":"bottom-left","caseSensitive":false,"showIcon":false,"autoSearch":true}) })</script>
    <script src="libs/htmlwidgets/htmlwidgets.js"></script>
    <script src="libs/plotly-binding/plotly.js"></script>
    <script src="libs/typedarray/typedarray.min.js"></script>
    <script src="libs/jquery/jquery.min.js"></script>
    <link href="libs/crosstalk/css/crosstalk.min.css" rel="stylesheet" />
    <script src="libs/crosstalk/js/crosstalk.min.js"></script>
    <link href="libs/plotly-htmlwidgets-css/plotly-htmlwidgets.css" rel="stylesheet" />
    <script src="libs/plotly-main/plotly-latest.min.js"></script>
    <link rel="stylesheet" href="style_files/fonts.css" type="text/css" />
    <link rel="stylesheet" href="style_files/my-theme.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# <p>How generative AI models such as ChatGPT can be (mis)used in SPC practice, education, and research?</p>
]
.author[
### Fadel M. Megahed, PhD <br><a href="https://scholar.google.com/citations?user=6CTlKGMAAAAJ&amp;hl=en&amp;oi=ao"><svg viewBox="0 0 488 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:white;" xmlns="http://www.w3.org/2000/svg"> <path d="M488 261.8C488 403.3 391.1 504 248 504 110.8 504 0 393.2 0 256S110.8 8 248 8c66.8 0 123 24.5 166.3 64.9l-67.5 64.9C258.5 52.6 94.3 116.6 94.3 256c0 86.5 69.1 156.6 153.7 156.6 98.2 0 135-70.4 140.8-106.9H248v-85.3h236.1c2.3 12.7 3.9 24.9 3.9 41.4z"></path></svg> Scholar</a>   |   <a href="https://twitter.com/FadelMegahed"><svg viewBox="0 0 512 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:white;" xmlns="http://www.w3.org/2000/svg"> <path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg> <span class="citation">@FadelMegahed</span></a>   |   <a href="https://github.com/fmegahed"><svg viewBox="0 0 496 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:white;" xmlns="http://www.w3.org/2000/svg"> <path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg> <span class="citation">@fmegahed</span></a>   |   <a href="mailto:fmegahed@miamioh.edu"><svg viewBox="0 0 512 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:white;" xmlns="http://www.w3.org/2000/svg"> <path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"></path></svg> fmegahed@miamioh.edu</a></br> <br> <u><b><font color="white">Joint work with:</b></u><br> Ying-Ju (Tessa) Chen, PhD   <a href="https://miamioh.edu/fsb/directory/?up=/directory/farmerl2"><svg viewBox="0 0 512 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:white;" xmlns="http://www.w3.org/2000/svg"> <path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg> University of Dayton</a><br/> Joshua A. Ferris, PhD   <a href="https://engineering.buffalo.edu/industrial-systems/people/faculty-directory/cavuoto-lora.html"><svg viewBox="0 0 512 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:white;" xmlns="http://www.w3.org/2000/svg"> <path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg> Miami University</a><br/> Sven Knoth, PhD   <a href="https://www.hsu-hh.de/compstat/en/sven-knoth-2"><svg viewBox="0 0 512 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:white;" xmlns="http://www.w3.org/2000/svg"> <path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg> Helmut-Schmidt-Universität</a><br/> Allison Jones-Farmer, PhD   <a href="https://miamioh.edu/fsb/directory/?up=/directory/farmerl2"><svg viewBox="0 0 512 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:white;" xmlns="http://www.w3.org/2000/svg"> <path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg> Miami University</a><br><br/>
]
.date[
### July 4, 2023 | ISSPM 2023 | Valencia
]

---








# Background: Artificial Intelligence

.bold[.red[Prompt:] A robot typing on a computer in front of a beach in the style of Pablo Picasso.]

&lt;img src="figs/fmegahed_A_robot_typing_on_a_computer_in_front_of_a_beach_81712b26-91ab-4092-a8db-bf733278dadc.png" alt="A generated art by Midjourney, a generative AI tool, showing a robot typing on a computer in front of a beach in the style of Pablo Picasso" width="42%" style="display: block; margin: auto;" /&gt;

.footnote[
&lt;html&gt;
&lt;hr&gt;
&lt;/html&gt;

**Image Source:** Image is generated using [Midjourney AI](https://docs.midjourney.com/docs/quick-start) by Fadel Megahed on June 30, 2023. 
]

---
count: false

# Background: Artificial Intelligence

.bold[.red[Prompt:] A robot performing statistical analysis on a computer in front of a beach digital art.]

&lt;img src="figs/fmegahed_A_robot_performing_statistical_analysis_on_a_computer__70802736-5bf4-4669-b5d4-d59f7b849074.png" alt="A generated art by Midjourney, a generative AI tool, showing a robot performing statistical analysis on a computer in front of a beach digital art" width="42%" style="display: block; margin: auto;" /&gt;

.footnote[
&lt;html&gt;
&lt;hr&gt;
&lt;/html&gt;

**Image Source:** Image is generated using [Midjourney AI](https://docs.midjourney.com/docs/quick-start) by Fadel Megahed on June 30, 2023. 
]


---
count: false

# Background: Artificial Intelligence

.left-code[

.center[.bold[A working definition for AI]]

.content-box-gray[
.bold[.red[Artificial Intelligence (AI):]] .bold[A system that acts in a way, where people might denote as "intelligent" if another human were to do something similar.]
]

.center[.bold[Reported applications of AI span numerous fields]] 
e.g., see a sample applications as generated by ChatGPT in the flowchart to the right.

]

.right-plot[

&lt;img src="figs/ai_applications.png" alt="A flowchart highlighting the applications of AI, with highlight in red for fraud detection (in e-commerce), grading and assessment (in education), quality control and predictive maintenance (in manufacturing and production) as they relate the most to our SPC audience" width="100%" style="display: block; margin: auto;" /&gt;

]

.footnote[
&lt;html&gt;
&lt;hr&gt;
&lt;/html&gt;

**Image Source:** The flowchart's content and its LaTex code were generated using ChatGPT (May 24 Version). You can view the chat used to populate the ideas and make the figure [here](https://chat.openai.com/share/42574eda-ff9a-4fc0-a7cc-e2b1e8bda6fc).
]


---

# Background: The Road to Generative AI

&lt;br&gt;

&lt;img src="figs/generative_ai_chart.png" alt="From big data to big models, a flow chart documenting how we got to large language models" width="100%" style="display: block; margin: auto;" /&gt;

.footnote[
&lt;html&gt;
&lt;hr&gt;
&lt;/html&gt;

**Comment:** You have been hearing about **big data** in SPC for over a decade now. In fact, we presented our paper titled [Statistical Perspectives on Big Data](https://citeseerx.ist.psu.edu/document?repid=rep1&amp;type=pdf&amp;doi=ab40f392e653b7336cbebf7c4fb95d3988748282) was presented almost exactly 10 years ago in the ISQC Workshop in Sydney. We now have models that can digest and generate answers based on more than 45TB of text. 
]

---

# Background: Generative AI

.content-box-gray[
.bold[.red[Generative AI:]] .bold[The objective is to generate new content rather than analyze existing data.]
]

.font90[
-  The generated content is based on a .bold[.red[stochastic behavior embedded in generative AI models such that the same input prompts results in different content]].
- State-of-the-art generative AI models can have up to **540 billion parameters** ([PaLM](https://arxiv.org/abs/2204.02311)).  
- With the increase in model size, researchers have observed the **“emergent abilities”** of LLMs, which were **not explicitly encoded in the training**. [Examples include](https://ai.googleblog.com/2022/11/characterizing-emergent-phenomena-in.html):
  + Multi-step arithmetic,   
  + taking college-level exams, and 
  + identifying the intended meaning of a word.  
- LLMs are **foundation models** (see [Bommasani et al. 2021](https://arxiv.org/abs/2108.07258)), large pre-trained AI systems
that can be **repurposed with minimal effort across numerous domains and diverse tasks**
]


---

# Background: Generative AI Developments



<div id="htmlwidget-f75d6a88ba78866ff0e7" style="width:100%;height:500px;" class="plotly html-widget "></div>
<script type="application/json" data-for="htmlwidget-f75d6a88ba78866ff0e7">{"x":{"data":[{"x":[19025],"y":[0],"text":"Date: 2022-02-02<br />AI Method: AlphaCode<br />Company: DeepMind<br />Description: A competition-level code generation by DeepMind","type":"scatter","mode":"markers","marker":{"autocolorscale":false,"color":"rgba(27,158,119,1)","opacity":1,"size":3.77952755905512,"symbol":"circle","line":{"width":1.88976377952756,"color":"rgba(27,158,119,1)"}},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[19226],"y":[0],"text":"Date: 2022-08-22<br />AI Method: Stable Diffusion<br />Company: U. Munich + Stability.AI<br />Description: A state of the art text-to-image model that generates images from text","type":"scatter","mode":"markers","marker":{"autocolorscale":false,"color":"rgba(102,102,102,1)","opacity":1,"size":3.77952755905512,"symbol":"circle","line":{"width":1.88976377952756,"color":"rgba(102,102,102,1)"}},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[19395],"y":[0],"text":"Date: 2023-02-07<br />AI Method: Bing Chat<br />Company: Microsoft<br />Description: Integrating GPT models with Bing Search","type":"scatter","mode":"markers","marker":{"autocolorscale":false,"color":"rgba(102,166,30,1)","opacity":1,"size":3.77952755905512,"symbol":"circle","line":{"width":1.88976377952756,"color":"rgba(102,166,30,1)"}},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[19116,19383,19437,19487,19502],"y":[0,0,0,0,0],"text":["Date: 2022-05-04<br />AI Method: PaLM<br />Company: Google<br />Description: Google's 540 billion parameter LLM","Date: 2023-01-26<br />AI Method: MusicLM<br />Company: Google<br />Description: From text to music","Date: 2023-03-21<br />AI Method: Bard<br />Company: Google<br />Description: Google's Chatbot, which competes with ChatGPT","Date: 2023-05-10<br />AI Method: PaLM 2<br />Company: Google<br />Description: Google's current LLM","Date: 2023-05-25<br />AI Method: Google AI Search<br />Company: Google<br />Description: Integrating PaLM models with Google Search"],"type":"scatter","mode":"markers","marker":{"autocolorscale":false,"color":"rgba(117,112,179,1)","opacity":1,"size":3.77952755905512,"symbol":"circle","line":{"width":1.88976377952756,"color":"rgba(117,112,179,1)"}},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[18424,18632,18632,19095,19326,19430],"y":[0,0,0,0,0,0],"text":["Date: 2020-06-11<br />AI Method: GPT-3<br />Company: OpenAI<br />Description: Generative Pre-trained Transformer 3 is an autoregressive language model that uses deep learning to produce human-like text","Date: 2021-01-05<br />AI Method: CLIP<br />Company: OpenAI<br />Description: Connects text to images","Date: 2021-01-05<br />AI Method: DALL.E<br />Company: OpenAI<br />Description: Generating images and art from text","Date: 2022-04-13<br />AI Method: DALL.E 2<br />Company: OpenAI<br />Description: Generating images and art from text, with ability to combine concepts, attributes and styles","Date: 2022-11-30<br />AI Method: ChatGPT<br />Company: OpenAI<br />Description: Chatbot built on top of GPT models","Date: 2023-03-14<br />AI Method: GPT-4<br />Company: OpenAI<br />Description: Open AI's current LLM Model"],"type":"scatter","mode":"markers","marker":{"autocolorscale":false,"color":"rgba(166,118,29,1)","opacity":1,"size":3.77952755905512,"symbol":"circle","line":{"width":1.88976377952756,"color":"rgba(166,118,29,1)"}},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[19164],"y":[0],"text":"Date: 2022-06-21<br />AI Method: CoPilot<br />Company: GitHub<br />Description: A LLM trained on GitHub data","type":"scatter","mode":"markers","marker":{"autocolorscale":false,"color":"rgba(217,95,2,1)","opacity":1,"size":3.77952755905512,"symbol":"circle","line":{"width":1.88976377952756,"color":"rgba(217,95,2,1)"}},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[19024],"y":[0],"text":"Date: 2022-02-01<br />AI Method: MidJourney<br />Company: Midjourney<br />Description: From text to images","type":"scatter","mode":"markers","marker":{"autocolorscale":false,"color":"rgba(230,171,2,1)","opacity":1,"size":3.77952755905512,"symbol":"circle","line":{"width":1.88976377952756,"color":"rgba(230,171,2,1)"}},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[19264,19383],"y":[0,0],"text":["Date: 2022-09-29<br />AI Method: Make-A-Video<br />Company: Meta<br />Description: AI system that lets people turn text prompts into brief, high-quality video clips","Date: 2023-01-26<br />AI Method: Make-A-Video3D<br />Company: Meta<br />Description: From text to videos"],"type":"scatter","mode":"markers","marker":{"autocolorscale":false,"color":"rgba(231,41,138,1)","opacity":1,"size":3.77952755905512,"symbol":"circle","line":{"width":1.88976377952756,"color":"rgba(231,41,138,1)"}},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[18355.5,19642.5],"y":[0,0],"text":"","type":"scatter","mode":"lines","line":{"width":2.64566929133858,"color":"rgba(0,0,0,1)","dash":"solid"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[19025],"y":[1.1],"text":"AlphaCode","hovertext":"Date: 2022-02-02<br />AI Method: AlphaCode<br />Company: DeepMind<br />Description: A competition-level code generation by DeepMind","textfont":{"size":13.2283464566929,"color":"rgba(27,158,119,1)"},"type":"scatter","mode":"text","hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[19226],"y":[1.1],"text":"Stable Diffusion","hovertext":"Date: 2022-08-22<br />AI Method: Stable Diffusion<br />Company: U. Munich + Stability.AI<br />Description: A state of the art text-to-image model that generates images from text","textfont":{"size":13.2283464566929,"color":"rgba(102,102,102,1)"},"type":"scatter","mode":"text","hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[19395],"y":[-1.1],"text":"Bing Chat","hovertext":"Date: 2023-02-07<br />AI Method: Bing Chat<br />Company: Microsoft<br />Description: Integrating GPT models with Bing Search","textfont":{"size":13.2283464566929,"color":"rgba(102,166,30,1)"},"type":"scatter","mode":"text","hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[19116,19383,19437,19487,19502],"y":[0.6,-0.6,-0.85,1.25,-1.25],"text":["PaLM","MusicLM","Bard","PaLM 2","Google AI Search"],"hovertext":["Date: 2022-05-04<br />AI Method: PaLM<br />Company: Google<br />Description: Google's 540 billion parameter LLM","Date: 2023-01-26<br />AI Method: MusicLM<br />Company: Google<br />Description: From text to music","Date: 2023-03-21<br />AI Method: Bard<br />Company: Google<br />Description: Google's Chatbot, which competes with ChatGPT","Date: 2023-05-10<br />AI Method: PaLM 2<br />Company: Google<br />Description: Google's current LLM","Date: 2023-05-25<br />AI Method: Google AI Search<br />Company: Google<br />Description: Integrating PaLM models with Google Search"],"textfont":{"size":13.2283464566929,"color":"rgba(117,112,179,1)"},"type":"scatter","mode":"text","hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[18424,18632,18632,19095,19326,19430],"y":[1.1,-1.1,0.6,-1.1,0.6,0.6],"text":["GPT-3","CLIP","DALL.E","DALL.E 2","ChatGPT","GPT-4"],"hovertext":["Date: 2020-06-11<br />AI Method: GPT-3<br />Company: OpenAI<br />Description: Generative Pre-trained Transformer 3 is an autoregressive language model that uses deep learning to produce human-like text","Date: 2021-01-05<br />AI Method: CLIP<br />Company: OpenAI<br />Description: Connects text to images","Date: 2021-01-05<br />AI Method: DALL.E<br />Company: OpenAI<br />Description: Generating images and art from text","Date: 2022-04-13<br />AI Method: DALL.E 2<br />Company: OpenAI<br />Description: Generating images and art from text, with ability to combine concepts, attributes and styles","Date: 2022-11-30<br />AI Method: ChatGPT<br />Company: OpenAI<br />Description: Chatbot built on top of GPT models","Date: 2023-03-14<br />AI Method: GPT-4<br />Company: OpenAI<br />Description: Open AI's current LLM Model"],"textfont":{"size":13.2283464566929,"color":"rgba(166,118,29,1)"},"type":"scatter","mode":"text","hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[19164],"y":[-0.6],"text":"CoPilot","hovertext":"Date: 2022-06-21<br />AI Method: CoPilot<br />Company: GitHub<br />Description: A LLM trained on GitHub data","textfont":{"size":13.2283464566929,"color":"rgba(217,95,2,1)"},"type":"scatter","mode":"text","hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[19024],"y":[-0.6],"text":"MidJourney","hovertext":"Date: 2022-02-01<br />AI Method: MidJourney<br />Company: Midjourney<br />Description: From text to images","textfont":{"size":13.2283464566929,"color":"rgba(230,171,2,1)"},"type":"scatter","mode":"text","hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[19264,19383],"y":[-1.1,1.1],"text":["Make-A-Video","Make-A-Video3D"],"hovertext":["Date: 2022-09-29<br />AI Method: Make-A-Video<br />Company: Meta<br />Description: AI system that lets people turn text prompts into brief, high-quality video clips","Date: 2023-01-26<br />AI Method: Make-A-Video3D<br />Company: Meta<br />Description: From text to videos"],"textfont":{"size":13.2283464566929,"color":"rgba(231,41,138,1)"},"type":"scatter","mode":"text","hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[19025,19025],"y":[1,0],"text":"Date: 2022-02-02<br />AI Method: AlphaCode<br />Company: DeepMind<br />Description: A competition-level code generation by DeepMind<br />Date: 19025","type":"scatter","mode":"lines","line":{"width":1.88976377952756,"color":"rgba(27,158,119,1)","dash":"solid"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[19226,19226],"y":[1,0],"text":"Date: 2022-08-22<br />AI Method: Stable Diffusion<br />Company: U. Munich + Stability.AI<br />Description: A state of the art text-to-image model that generates images from text<br />Date: 19226","type":"scatter","mode":"lines","line":{"width":1.88976377952756,"color":"rgba(102,102,102,1)","dash":"solid"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[19395,19395],"y":[-1,0],"text":"Date: 2023-02-07<br />AI Method: Bing Chat<br />Company: Microsoft<br />Description: Integrating GPT models with Bing Search<br />Date: 19395","type":"scatter","mode":"lines","line":{"width":1.88976377952756,"color":"rgba(102,166,30,1)","dash":"solid"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[19116,19116,null,19383,19383,null,19437,19437,null,19487,19487,null,19502,19502],"y":[0.5,0,null,-0.5,0,null,-0.75,0,null,1.15,0,null,-1.15,0],"text":["Date: 2022-05-04<br />AI Method: PaLM<br />Company: Google<br />Description: Google's 540 billion parameter LLM<br />Date: 19116","Date: 2022-05-04<br />AI Method: PaLM<br />Company: Google<br />Description: Google's 540 billion parameter LLM<br />Date: 19116",null,"Date: 2023-01-26<br />AI Method: MusicLM<br />Company: Google<br />Description: From text to music<br />Date: 19383","Date: 2023-01-26<br />AI Method: MusicLM<br />Company: Google<br />Description: From text to music<br />Date: 19383",null,"Date: 2023-03-21<br />AI Method: Bard<br />Company: Google<br />Description: Google's Chatbot, which competes with ChatGPT<br />Date: 19437","Date: 2023-03-21<br />AI Method: Bard<br />Company: Google<br />Description: Google's Chatbot, which competes with ChatGPT<br />Date: 19437",null,"Date: 2023-05-10<br />AI Method: PaLM 2<br />Company: Google<br />Description: Google's current LLM<br />Date: 19487","Date: 2023-05-10<br />AI Method: PaLM 2<br />Company: Google<br />Description: Google's current LLM<br />Date: 19487",null,"Date: 2023-05-25<br />AI Method: Google AI Search<br />Company: Google<br />Description: Integrating PaLM models with Google Search<br />Date: 19502","Date: 2023-05-25<br />AI Method: Google AI Search<br />Company: Google<br />Description: Integrating PaLM models with Google Search<br />Date: 19502"],"type":"scatter","mode":"lines","line":{"width":1.88976377952756,"color":"rgba(117,112,179,1)","dash":"solid"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[18424,18424,null,18632,18632,null,18632,18632,null,19095,19095,null,19326,19326,null,19430,19430],"y":[1,0,null,-1,0,null,0.5,0,null,-1,0,null,0.5,0,null,0.5,0],"text":["Date: 2020-06-11<br />AI Method: GPT-3<br />Company: OpenAI<br />Description: Generative Pre-trained Transformer 3 is an autoregressive language model that uses deep learning to produce human-like text<br />Date: 18424","Date: 2020-06-11<br />AI Method: GPT-3<br />Company: OpenAI<br />Description: Generative Pre-trained Transformer 3 is an autoregressive language model that uses deep learning to produce human-like text<br />Date: 18424",null,"Date: 2021-01-05<br />AI Method: CLIP<br />Company: OpenAI<br />Description: Connects text to images<br />Date: 18632","Date: 2021-01-05<br />AI Method: CLIP<br />Company: OpenAI<br />Description: Connects text to images<br />Date: 18632",null,"Date: 2021-01-05<br />AI Method: DALL.E<br />Company: OpenAI<br />Description: Generating images and art from text<br />Date: 18632","Date: 2021-01-05<br />AI Method: DALL.E<br />Company: OpenAI<br />Description: Generating images and art from text<br />Date: 18632",null,"Date: 2022-04-13<br />AI Method: DALL.E 2<br />Company: OpenAI<br />Description: Generating images and art from text, with ability to combine concepts, attributes and styles<br />Date: 19095","Date: 2022-04-13<br />AI Method: DALL.E 2<br />Company: OpenAI<br />Description: Generating images and art from text, with ability to combine concepts, attributes and styles<br />Date: 19095",null,"Date: 2022-11-30<br />AI Method: ChatGPT<br />Company: OpenAI<br />Description: Chatbot built on top of GPT models<br />Date: 19326","Date: 2022-11-30<br />AI Method: ChatGPT<br />Company: OpenAI<br />Description: Chatbot built on top of GPT models<br />Date: 19326",null,"Date: 2023-03-14<br />AI Method: GPT-4<br />Company: OpenAI<br />Description: Open AI's current LLM Model<br />Date: 19430","Date: 2023-03-14<br />AI Method: GPT-4<br />Company: OpenAI<br />Description: Open AI's current LLM Model<br />Date: 19430"],"type":"scatter","mode":"lines","line":{"width":1.88976377952756,"color":"rgba(166,118,29,1)","dash":"solid"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[19164,19164],"y":[-0.5,0],"text":"Date: 2022-06-21<br />AI Method: CoPilot<br />Company: GitHub<br />Description: A LLM trained on GitHub data<br />Date: 19164","type":"scatter","mode":"lines","line":{"width":1.88976377952756,"color":"rgba(217,95,2,1)","dash":"solid"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[19024,19024],"y":[-0.5,0],"text":"Date: 2022-02-01<br />AI Method: MidJourney<br />Company: Midjourney<br />Description: From text to images<br />Date: 19024","type":"scatter","mode":"lines","line":{"width":1.88976377952756,"color":"rgba(230,171,2,1)","dash":"solid"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[19264,19264,null,19383,19383],"y":[-1,0,null,1,0],"text":["Date: 2022-09-29<br />AI Method: Make-A-Video<br />Company: Meta<br />Description: AI system that lets people turn text prompts into brief, high-quality video clips<br />Date: 19264","Date: 2022-09-29<br />AI Method: Make-A-Video<br />Company: Meta<br />Description: AI system that lets people turn text prompts into brief, high-quality video clips<br />Date: 19264",null,"Date: 2023-01-26<br />AI Method: Make-A-Video3D<br />Company: Meta<br />Description: From text to videos<br />Date: 19383","Date: 2023-01-26<br />AI Method: Make-A-Video3D<br />Company: Meta<br />Description: From text to videos<br />Date: 19383"],"type":"scatter","mode":"lines","line":{"width":1.88976377952756,"color":"rgba(231,41,138,1)","dash":"solid"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null}],"layout":{"margin":{"t":32.5317068865769,"r":7.55905511811024,"b":14.9376844706367,"l":6.43623158562216},"plot_bgcolor":"rgba(255,255,255,1)","paper_bgcolor":"rgba(255,255,255,1)","font":{"color":"rgba(0,0,0,1)","family":"","size":10.6268161062682},"title":{"text":"<b> A Representative Sample of Major Generative AI Developments from 2020 to May 2023 <\/b>","font":{"color":"rgba(0,0,0,1)","family":"","size":12.7521793275218},"x":0.5,"xref":"paper"},"xaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[18355.5,19642.5],"tickmode":"array","ticktext":["Jul 2020","Oct 2020","Jan 2021","Apr 2021","Jul 2021","Oct 2021","Jan 2022","Apr 2022","Jul 2022","Oct 2022","Jan 2023","Apr 2023","Jul 2023","Oct 2023"],"tickvals":[18444,18536,18628,18718,18809,18901,18993,19083,19174,19266,19358,19448,19539,19631],"categoryorder":"array","categoryarray":["Jul 2020","Oct 2020","Jan 2021","Apr 2021","Jul 2021","Oct 2021","Jan 2022","Apr 2022","Jul 2022","Oct 2022","Jan 2023","Apr 2023","Jul 2023","Oct 2023"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":2.65670402656704,"tickwidth":0.483037095739462,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":8.50145288501453},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":false,"gridcolor":null,"gridwidth":0,"zeroline":false,"anchor":"y","title":{"text":"<b>  <\/b>","font":{"color":"rgba(0,0,0,1)","family":"","size":10.6268161062682}},"hoverformat":".2f"},"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[-1.375,1.375],"tickmode":"array","ticktext":["-1.0","-0.5","0.0","0.5","1.0"],"tickvals":[-1,-0.5,0,0.5,1],"categoryorder":"array","categoryarray":["-1.0","-0.5","0.0","0.5","1.0"],"nticks":null,"ticks":"","tickcolor":null,"ticklen":2.65670402656704,"tickwidth":0,"showticklabels":false,"tickfont":{"color":null,"family":null,"size":0},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":false,"gridcolor":null,"gridwidth":0,"zeroline":false,"anchor":"x","title":{"text":"","font":{"color":null,"family":null,"size":0}},"hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":"transparent","line":{"color":"rgba(51,51,51,1)","width":0.483037095739462,"linetype":"solid"},"yref":"paper","xref":"paper","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"legend":{"bgcolor":"rgba(255,255,255,1)","bordercolor":"transparent","borderwidth":1.37437365783822,"font":{"color":"rgba(0,0,0,1)","family":"","size":8.50145288501453},"title":{"text":"Company","font":{"color":"rgba(0,0,0,1)","family":"","size":10.6268161062682}}},"hovermode":"closest","height":500,"barmode":"relative","annotations":[{"x":1,"y":-0.085,"text":"By: Fadel M. Megahed  | Version 2.0: An updated and interactive version of what we have in the QE paper | Data Source: Publicly available release dates of major AI developments","showarrow":false,"xref":"paper","yref":"paper","xanchor":"right","yanchor":"auto","xshift":0,"yshift":0,"font":{"size":9,"color":"black"}},{"x":1,"y":-0.085,"text":"By: Fadel M. Megahed  | Version 2.0: An updated and interactive version of what we have in the QE paper | Data Source: Publicly available release dates of major AI developments","showarrow":false,"xref":"paper","yref":"paper","xanchor":"right","yanchor":"auto","xshift":0,"yshift":0,"font":{"size":9,"color":"black"}}]},"config":{"doubleClick":"reset","modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"source":"A","attrs":{"3190ab54a88":{"x":{},"y":{},"label":{},"colour":{},"type":"scatter"},"319041095f8c":{"yintercept":{}},"3190521d538d":{"x":{},"y":{},"label":{},"colour":{}},"3190398827a4":{"x":{},"y":{},"label":{},"colour":{},"yend":{},"xend":{}}},"cur_data":"3190ab54a88","visdat":{"3190ab54a88":["function (y) ","x"],"319041095f8c":["function (y) ","x"],"3190521d538d":["function (y) ","x"],"3190398827a4":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>

---

# Background: Generative AI Hype

&lt;img src="generative_ai_spc_files/figure-html/gen_ai_hype-1.png" alt="It took ChatGPT 5 days to reach 1 million users, while Instagram took 2.5 months and twitter took 24 months. We have not seen such a huge adoption that quick in tech before." width="100%" style="display: block; margin: auto;" /&gt;

---
count: false

# Background: Generative AI Hype

&lt;img src="figs/fortune_mistral.png" alt="A header of a news article from Fortune Magazine, which shows that the French Generative AI company, Mistral, raised over 100 million US Dollars less than a month since it has been founded, with limited employees and no products" width="100%" style="display: block; margin: auto;" /&gt;
.center[.white[vertical spacing]]

.center[.font90[Excitement about generative AI continues (click [here to access the Fortune article on Mistral](https://fortune.com/2023/06/14/mistral-ai-startup-record-113-million-seed-round-arthur-mensch/))]]


---
count: false

# Background: Generative AI Hype

&lt;center&gt;
&lt;style&gt;
.infogram-embed {
    margin-top: -1em;
}
&lt;/style&gt;
&lt;div class="infogram-embed" data-id="4ae4419f-d149-4d84-b508-6af13699b3de" data-type="interactive" data-title="Generative AI Valuations - May 2023"&gt;&lt;/div&gt;&lt;script&gt;!function(e,i,n,s){var t="InfogramEmbeds",d=e.getElementsByTagName("script")[0];if(window[t]&amp;&amp;window[t].initialized)window[t].process&amp;&amp;window[t].process();else if(!e.getElementById(n)){var o=e.createElement("script");o.async=1,o.id=n,o.src="https://e.infogram.com/js/dist/embed-loader-min.js",d.parentNode.insertBefore(o,d)}}(document,0,"infogram-async");&lt;/script&gt;
&lt;/center&gt;


---
class: inverse, center, middle

# Our Study Design and Main Findings

&lt;br&gt;

.pull-left-2[&lt;br&gt; Megahed, F. M., Chen, Y. J., Ferris, J. A., Knoth, S., &amp; Jones-Farmer, L. A. (2023). How generative AI models such as ChatGPT can be (mis)used in SPC practice, education, and research? An exploratory study. *Quality Engineering*, 1-29.

[Freely available @ [QE (end of Sept)](https://www.tandfonline.com/doi/full/10.1080/08982112.2023.2206479) &amp; [arXiv (forever)](https://arxiv.org/pdf/2302.10916.pdf)].]

.pull-right-2[&lt;div&gt;&lt;img src="figs/paper_qr_code.png" class="paper-img" width="300px" align="right"&gt;&lt;/div&gt;]



---

# Our Overarching Research Question

.content-box-red[
.bold[What can generative LLM-based AI tools do now to augment the roles of SPC practitioners, educators, and researchers?]

]

-  **Secondary goal:** To motivate the SPC community to be receptive to exploring whether new AI tools can help them be more **efficient**, **productive**, and **innovative**. This is consistent with:

  + Box and Woodall ([2012](https://www.tandfonline.com/doi/10.1080/08982112.2012.627003)): “we stress the necessity for the quality engineering community to strengthen and promote its role in **innovation**”, and  
  + Hockman and Jensen ([2016](https://www.tandfonline.com/doi/10.1080/08982112.2015.1083107)): “for statisticians to be successful in leading innovation, they will need to strengthen their **skills beyond what they have traditionally needed in the past**, but we believe this will be worth the effort”.  
  
- **Scope:** We evaluated the utility of ChatGPT (GPT-3.5 engine) as of its *Jan 30 Version*.   

---

# Our Study Design


&lt;center&gt;
&lt;img src="./figs/methods.png" alt="An overview of our study design, where we focused on three applications code, explanation, and knowledge generation for each application domain of practice, learning, and research. Red color is used to highlight the questions that will be discussed in the presentation." width="70%" height="70%" border="0" style="padding:0px; display: block; line-height: 0px; font-size: 0px; border:0px;" /&gt;
&lt;/center&gt;


---

# The Good: Knowledge Generation


.bold[Inspired by the TEDxBoston talk titled [what we learned from 5 million books](https://www.ted.com/talks/jean_baptiste_michel_erez_lieberman_aiden_what_we_learned_from_5_million_books?language=en), we asked ChatGPT the following question:]

&lt;br&gt;

&gt; .bold[.large["What are open issues in statistical process control research?'']]

&lt;br&gt;

### Why this question seemed like a reasonable prompt?
.bold[ChatGPT likely “read” and “can recall” more SPC research papers than most of us .red[(may be not more than Bill Woodall)]] 😄

---
count: false

# The Good: Knowledge Generation

&lt;center&gt;
&lt;iframe width="889" height="500" src="https://www.loom.com/embed/fbe45e1f38ff46edbe6523513e4153e1?sid=065b8f5c-b58d-4351-8b1a-063d44602a58" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
&lt;/center&gt;


---
count: false

# The Good: Knowledge Generation

&lt;img src="figs/research_prompt_08_fig_01.png" alt="Chat GPT highlighted six areas where there are open issues in statistical process control. We will highlight the main themese in the next slide" width="63%" style="display: block; margin: auto;" /&gt;


---
count: false

# The Good: Knowledge Generation

.content-box-red[
.center[.bold[.large[Some Thoughts on the ChatGPT Answer]]]

- It captured .bold[reasonable themes, e.g., ]
  + incorporating .bold[big data and machine learning] techniques, 
  + .bold[online/real-time monitoring] solutions where 100% sampling is employed, 
  + the need for .bold[non-normality], and 
  + .bold[applications to new domains].  

- In our opinion, .bold[value is in using it as a high-level tool for idea generation/validation].  
- Potentially .bold[“stale”] as the [ChatGPT/GPT-3.5 model “finished training in early 2022”](https://openai.com/blog/chatgpt/).  
  + Probably not an issue for future LLM generations (.bold[Why?])
]


---

# The Good: Code Explanation

&gt; .bold[.large[Explain the following <svg aria-hidden="true" role="img" viewBox="0 0 581 512" style="height:1em;width:1.13em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M581 226.6C581 119.1 450.9 32 290.5 32S0 119.1 0 226.6C0 322.4 103.3 402 239.4 418.1V480h99.1v-61.5c24.3-2.7 47.6-7.4 69.4-13.9L448 480h112l-67.4-113.7c54.5-35.4 88.4-84.9 88.4-139.7zm-466.8 14.5c0-73.5 98.9-133 220.8-133s211.9 40.7 211.9 133c0 50.1-26.5 85-70.3 106.4-2.4-1.6-4.7-2.9-6.4-3.7-10.2-5.2-27.8-10.5-27.8-10.5s86.6-6.4 86.6-92.7-90.6-87.9-90.6-87.9h-199V361c-74.1-21.5-125.2-67.1-125.2-119.9zm225.1 38.3v-55.6c57.8 0 87.8-6.8 87.8 27.3 0 36.5-38.2 28.3-87.8 28.3zm-.9 72.5H365c10.8 0 18.9 11.7 24 19.2-16.1 1.9-33 2.8-50.6 2.9v-22.1z"/></svg> function for approximating the ARL of a two-sided EWMA control chart for monitoring the mean of normally distributed random variables ....]]


```r
ewma.arl &lt;- function(lam, cE, mu, z0=0, r=50) {
  cE &lt;- cE*sqrt(lam/(2-lam))
  ii &lt;- (-r:r)
  w &lt;- 2*cE/(2*r+1)
  qij &lt;- function(i,j) pnorm((j*w-(1-lam)*i*w+w/2)/lam-mu) - 
    pnorm((j*w-(1-lam)*i*w-w/2)/lam-mu)
  Q &lt;- outer(ii,ii,qij)
  one &lt;- array(1,2*r+1)
  I &lt;- diag(1,2*r+1)
  ARL &lt;- solve(I-Q,one)
  arl &lt;- ARL[r+round((z0+w/2)/w)]
  arl
}
```


---
count: false

# The Good: Code Explanation

&lt;center&gt;
&lt;iframe width="889" height="500" src="https://www.loom.com/embed/19b585fa52514c36bd5621e3612ad5bb?sid=e0636085-5dcd-4a7a-ade1-239160ccb825" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
&lt;/center&gt;


---
count: false

# The Good: Code Explanation


```r
ewma.arl &lt;- function(lam, cE, mu, z0=0, r=50) {
  cE &lt;- cE*sqrt(lam/(2-lam))
  ii &lt;- (-r:r)
  w &lt;- 2*cE/(2*r+1)
  qij &lt;- function(i,j) pnorm((j*w-(1-lam)*i*w+w/2)/lam-mu) - 
    pnorm((j*w-(1-lam)*i*w-w/2)/lam-mu)
  Q &lt;- outer(ii,ii,qij)
  one &lt;- array(1,2*r+1)
  I &lt;- diag(1,2*r+1)
  ARL &lt;- solve(I-Q,one)
  arl &lt;- ARL[r+round((z0+w/2)/w)]
  arl
}
```

&lt;img src="figs/research_prompt_03_fig_01.png" alt="We asked ChatGPT to tell us the mathematical method for the code prompt above and ChatGPT answered Markov Chain analysis which is close to the precise answer of Markov Chain approximation" width="80%" style="display: block; margin: auto;" /&gt;

---
count: false

# The Good: Code Explanation

.pull-left[
.content-box-red[
.center[.bold[Thoughts on the ChatGPT Answer]]

- It did a .bold[good job, explaining the function], where it
  + explained the four inputs and their limits/default when available, and
  + the .bold[eight] steps needed to compute the ARL.

- The answer to our follow-up question was .bold[remarkably short] and .bold[close to the complete answer "Markov chain approximation''].
]
]

.pull-right[
&lt;img src="figs/research_prompt_02_fig_01.png" alt="A screen shot from the video from a couple of slide ago, showing ChatGPT did a good job of explaining our ewma dot arl function" width="90%" style="display: block; margin: auto;" /&gt;
]


---

# The Starting-Point: Coding

&gt; .bold[.large[Calculate the zero-state ARL of an EWMA control chart with smoothing constant 0.1 and control limit factor 3 in the in-control case. The data is normally distributed. Use Monte Carlo simulation.]]

&lt;br&gt;

### Why this question seemed like a reasonable prompt?

.bold[We wanted to assess ChatGPT's ability to assist in generating code for SPC-specific applications] (this research ask was more challenging, by design, than the prompts for code in the learning and teaching tasks). 


---
count: false

# The Starting-Point: Coding

.font80[

```python
import numpy as np
import matplotlib.pyplot as plt

def ewma(x, y, alpha):
    return (1 - alpha) * x + alpha * y

def simulate_ewma(n, alpha, k, num_simulations):
    arls = []
    for i in range(num_simulations):
        x = np.random.normal(0, 1, n)
        ewma_stat = np.zeros(n)
        ewma_stat[0] = x[0]
        for j in range(1, n):
            ewma_stat[j] = ewma(x[j], ewma_stat[j-1], alpha)
        control_limit = k * np.std(x)
        run_length = 0
        for j in range(n):
            if np.abs(ewma_stat[j]) &gt; control_limit:
                run_length = j + 1
                break
        arls.append(run_length)
    return np.mean(arls)

n = 1000
alpha = 0.1
k = 3
num_simulations = 10000

arl = simulate_ewma(n, alpha, k, num_simulations)
print("Zero-state ARL:", arl)
```
]


---
count: false

# The Starting-Point: Coding

.content-box-red[
.center[.bold[Thoughts on the ChatGPT Answer]]

- The Python code **ran without errors.**

- However, it produced **incorrect results due to multiple errors**, which can be divided into:   
  + **Major**, where the run-lengths were truncated at `\(n\)` `\((n=1,000)\)` (making the results smaller), and the use of the entire data to estimate the sample standard deviation (i.e., future/unseen data is used for establishing the control limit). 
  + **Minor,** included using initializing the EWMA with the first observation. 
]



---

# The Bad: Precise Definitions

&lt;img src="figs/research_prompt_05_fig_01.png" alt="ChatGPT's generated response for our prompt of explain the practitioner-to-practitioner variability. Its response is somewhat long and imprecise. Specifically, ChatGPT presented five factors, which share a common feature; all deal with differences on the method level, i.e., chart type, subgroup design, techniques to calculate the limits, dealing with outliers, and choice of software. While we agree that these factors are important and will drive different results, ChatGPT's answer ignores the context for which the practitioner-to-practitioner variability is used in the SPC literature. In fact, the practitioner-to-practitioner variability refers to the variation that occurs with a fixed configuration of the five aforementioned factors, i.e., the variation results from multiple implementations of the same procedure on the same data-generating process." width="46%" style="display: block; margin: auto;" /&gt;



---

# The Ugly: ChatGPT's Halucination

.bold[To detect whether ChatGPT can detect erroneous requests, we asked:]

&lt;br&gt;

&gt; .bold[.large["Can you use the ‘bigfish' dataset from the qcc library in \texttt{R} to create a control chart?'' Note that we made up this dataset name.]]

&lt;br&gt;

### Why this question seemed like a reasonable prompt?
.bold[In an earlier question (within the same thread), ChatGPT answered a question by using the `qcc` package, i.e., is .red[familiar with it], and .red[detecting unreasonable requests would be a strong feature for non-expert users].]


---
count: false

# The Ugly: ChatGPT's Halucination

&lt;img src="figs/practice_prompt_03_fig_01.png" alt="The ChatGPT halucination, answering a question about a non-existent dataset in the qcc library" width="60%" style="display: block; margin: auto;" /&gt;


---
count: false

# The Ugly: ChatGPT's Halucination

&lt;img src="figs/practice_prompt_03_fig_02.png" alt="ChatGPT making up details about the non-existent bigfish dataset and saying it is popular in the SPC community" width="80%" style="display: block; margin: auto;" /&gt;


---

# Conclusions

&lt;img src="figs/conclusions.png" alt="A flowchart highlighting the strengths of ChatGPT and its weakness, following from our highlighted questions" width="80%" style="display: block; margin: auto;" /&gt;


---

# Open Questions

&lt;img src="figs/open_questions.png" alt="Five open questions that relate to output quality assessment, variability assessment, how to tailor generative AI methods to SPC applications, ethics of use, and legal issues from using it" width="50%" style="display: block; margin: auto;" /&gt;


---
count: false

# Open Questions - EU Legal Issues

&lt;img src="https://crfm.stanford.edu/static/img/posts/2023-06-15-eu-ai-act/results.png" width="92%" style="display: block; margin: auto;" /&gt;

.footnote[
&lt;html&gt;
&lt;hr&gt;
&lt;/html&gt;

**Image Source:** Stanford's Center for Research on Foundation Models (see [the post by Bommasani et al. 2023](https://crfm.stanford.edu/2023/06/15/eu-ai-act.html) for more details).
]

---
class: center, middle, inverse, title-slide

.title[
# &lt;p&gt;How generative AI models such as ChatGPT can be (mis)used in SPC practice, education, and research?&lt;/p&gt;
]
.author[
### Fadel M. Megahed, PhD &lt;br&gt;&lt;a href="https://scholar.google.com/citations?user=6CTlKGMAAAAJ&amp;amp;hl=en&amp;amp;oi=ao"&gt;&lt;svg viewBox="0 0 488 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:white;" xmlns="http://www.w3.org/2000/svg"&gt; &lt;path d="M488 261.8C488 403.3 391.1 504 248 504 110.8 504 0 393.2 0 256S110.8 8 248 8c66.8 0 123 24.5 166.3 64.9l-67.5 64.9C258.5 52.6 94.3 116.6 94.3 256c0 86.5 69.1 156.6 153.7 156.6 98.2 0 135-70.4 140.8-106.9H248v-85.3h236.1c2.3 12.7 3.9 24.9 3.9 41.4z"&gt;&lt;/path&gt;&lt;/svg&gt; Scholar&lt;/a&gt;   |   &lt;a href="https://twitter.com/FadelMegahed"&gt;&lt;svg viewBox="0 0 512 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:white;" xmlns="http://www.w3.org/2000/svg"&gt; &lt;path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"&gt;&lt;/path&gt;&lt;/svg&gt; &lt;span class="citation"&gt;@FadelMegahed&lt;/span&gt;&lt;/a&gt;   |   &lt;a href="https://github.com/fmegahed"&gt;&lt;svg viewBox="0 0 496 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:white;" xmlns="http://www.w3.org/2000/svg"&gt; &lt;path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"&gt;&lt;/path&gt;&lt;/svg&gt; &lt;span class="citation"&gt;@fmegahed&lt;/span&gt;&lt;/a&gt;   |   &lt;a href="mailto:fmegahed@miamioh.edu"&gt;&lt;svg viewBox="0 0 512 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:white;" xmlns="http://www.w3.org/2000/svg"&gt; &lt;path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"&gt;&lt;/path&gt;&lt;/svg&gt; fmegahed@miamioh.edu&lt;/a&gt;&lt;/br&gt; &lt;br&gt; &lt;u&gt;&lt;b&gt;&lt;font color="white"&gt;Joint work with:&lt;/b&gt;&lt;/u&gt;&lt;br&gt; Ying-Ju (Tessa) Chen, PhD   &lt;a href="https://miamioh.edu/fsb/directory/?up=/directory/farmerl2"&gt;&lt;svg viewBox="0 0 512 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:white;" xmlns="http://www.w3.org/2000/svg"&gt; &lt;path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"&gt;&lt;/path&gt;&lt;/svg&gt; University of Dayton&lt;/a&gt;&lt;br/&gt; Joshua A. Ferris, PhD   &lt;a href="https://engineering.buffalo.edu/industrial-systems/people/faculty-directory/cavuoto-lora.html"&gt;&lt;svg viewBox="0 0 512 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:white;" xmlns="http://www.w3.org/2000/svg"&gt; &lt;path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"&gt;&lt;/path&gt;&lt;/svg&gt; Miami University&lt;/a&gt;&lt;br/&gt; Sven Knoth, PhD   &lt;a href="https://www.hsu-hh.de/compstat/en/sven-knoth-2"&gt;&lt;svg viewBox="0 0 512 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:white;" xmlns="http://www.w3.org/2000/svg"&gt; &lt;path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"&gt;&lt;/path&gt;&lt;/svg&gt; Helmut-Schmidt-Universität&lt;/a&gt;&lt;br/&gt; Allison Jones-Farmer, PhD   &lt;a href="https://miamioh.edu/fsb/directory/?up=/directory/farmerl2"&gt;&lt;svg viewBox="0 0 512 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:white;" xmlns="http://www.w3.org/2000/svg"&gt; &lt;path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"&gt;&lt;/path&gt;&lt;/svg&gt; Miami University&lt;/a&gt;&lt;br&gt;&lt;br/&gt;
]
.date[
### July 4, 2023 | ISSPM 2023 | Valencia
]

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLanguage": "r",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
